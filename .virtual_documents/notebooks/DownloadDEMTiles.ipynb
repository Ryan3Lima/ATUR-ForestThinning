


#!pip install pandas requests


import os
import requests
import pandas as pd


# File paths and download directory
csv_file = 'Files/files.csv'  # Adjust this if needed
download_dir = r'G:\Data\CoconinoNF\MogollonRimRangerDistrict\NED1m'

# Ensure the download directory exists
os.makedirs(download_dir, exist_ok=True)

# Load the CSV file
tile_data = pd.read_csv(csv_file)


tile_data


# File paths and download directory
csv_file = 'Files/files.csv'  # Adjust this if needed
download_dir = r'G:\Data\CoconinoNF\MogollonRimRangerDistrict\NED1m'

# Ensure the download directory exists
os.makedirs(download_dir, exist_ok=True)

# Load the CSV file
tile_data = pd.read_csv(csv_file)

# Extract the column containing the download URLs
url_column = 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1m/Projects/AZ_Coconino_2019_B19/TIFF/USGS_1M_12_x44y386_AZ_Coconino_2019_B19.tif'

# Check if the column exists
if url_column not in tile_data.columns:
    print(f"Column '{url_column}' not found in the CSV file.")
else:
    # Download each file
    for index, url in tile_data[url_column].dropna().items():  # Use .items() instead of .iteritems()
        file_name = os.path.basename(url)  # Get the file name from the URL
        file_path = os.path.join(download_dir, file_name)
        
        # Download the file
        try:
            print(f"Downloading {url}...")
            response = requests.get(url, stream=True)
            response.raise_for_status()  # Raise an exception for HTTP errors
            
            # Save the file
            with open(file_path, 'wb') as file:
                for chunk in response.iter_content(chunk_size=8192):
                    file.write(chunk)
            print(f"Downloaded: {file_path}")
        except requests.RequestException as e:
            print(f"Failed to download {url}: {e}")

